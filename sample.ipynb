import tensorflow as tf
import tensorflow_datasets as tfds
import os
import pprint
import tensorflow as tf
import time
import numpy as np
from tensorflow import keras

TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']

DIRECTORY_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/'
FILE_NAMES = ['cowper.txt', 'derby.txt', 'butler.txt']

for name in FILE_NAMES:
  text_dir = tf.keras.utils.get_file(name, origin=DIRECTORY_URL+name)
  
parent_dir = os.path.dirname(text_dir)

print (parent_dir)
def labeler(example, index):
  return example, tf.cast(index, tf.int32)  

labeled_data_sets = []

for i, file_name in enumerate(FILE_NAMES):
  lines_dataset = tf.data.TextLineDataset(os.path.join(parent_dir, file_name))
  labeled_dataset = lines_dataset.map(lambda ex: labeler(ex, i))
  labeled_data_sets.append(labeled_dataset)

BUFFER_SIZE = 50000
BATCH_SIZE = 64
TAKE_SIZE = 5000
all_labeled_data = labeled_data_sets[0]
for labeled_dataset in labeled_data_sets[1:]:
  all_labeled_data = all_labeled_data.concatenate(labeled_dataset)
  
all_labeled_data = all_labeled_data.shuffle(
    BUFFER_SIZE, reshuffle_each_iteration=False)
print type(all_labeled_data)
tokenizer = tfds.features.text.Tokenizer()
tokenizer = tfds.features.text.Tokenizer()
############PROBLEM WAS HERE FIXED WITH FOLLOWING ITERATOR############
vocabulary_set = set()

my_iterator = all_labeled_data.make_initializable_iterator()
text_tensor, _ = my_iterator.get_next()
with tf.Session() as sess1: 
  sess1.run(my_iterator.initializer)
  try:
    while True:
      text_string = sess1.run(text_tensor)
      #print text_string
      some_tokens = tokenizer.tokenize(text_string)
      vocabulary_set.update(some_tokens)
  except tf.errors.OutOfRangeError:
    pass